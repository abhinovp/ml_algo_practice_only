{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KFold Cross validation: Train/test on various samples and use mean scores to get best scores.\n",
    "# Source: https://www.youtube.com/watch?v=gJo0uNL-5Qw&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&index=13\n",
    "# Excercise: IRIS and give best model name and score\n",
    "\n",
    "import pandas as ps\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as ny\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Describing the data set\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisdf = ps.DataFrame(iris.data)\n",
    "irisdf.head()\n",
    "\n",
    "# Defining targets\n",
    "\n",
    "targets = ps.DataFrame(iris.target)\n",
    "targets.shape #head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "#T-T-S\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(irisdf,targets,test_size=0.3)\n",
    "# Very important to give 2 dim array above if not setup into DFs.\n",
    "\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import 3 algos for cross validation:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "lm = LogisticRegression()\n",
    "lm.fit(X_train,y_train.values.ravel())\n",
    "lm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcm = SVC()\n",
    "svcm.fit(X_train,y_train.values.ravel())\n",
    "svcm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm = RandomForestClassifier(n_estimators=30)\n",
    "rfm.fit(X_train,y_train.values.ravel())\n",
    "rfm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = tree.DecisionTreeClassifier()\n",
    "dtm.fit(X_train,y_train.values.ravel())\n",
    "dtm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  5  6  7  8  9 10 11] [0 1 2]\n",
      "[ 0  1  2  6  7  8  9 10 11] [3 4 5]\n",
      "[ 0  1  2  3  4  5  9 10 11] [6 7 8]\n",
      "[0 1 2 3 4 5 6 7 8] [ 9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# The above samples change and score changes for %test data. How to arrive after confident iterations to a score ?\n",
    "# Enter Kfold\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "# Now prepare a iterator set using TTS that will hold split IDs for the models we assign.\n",
    "for train_ind, test_ind in kf.split(range(0,12)):\n",
    "    print(train_ind,test_ind)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Using a def to call each model \n",
    "\n",
    "def fetch_score(model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.score(X_test,y_test)\n",
    "\n",
    "# Lets call above def using SVM\n",
    "print(fetch_score(svcm,X_train,y_train.values.ravel(),X_test,y_test))\n",
    "print(fetch_score(rfm,X_train,y_train.values.ravel(),X_test,y_test))\n",
    "print(fetch_score(lm,X_train,y_train.values.ravel(),X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77777778 1.         0.88888889 1.         0.88888889]\n",
      "[0.88888889 1.         0.88888889 1.         0.88888889]\n",
      "[0.88888889 1.         0.88888889 1.         0.88888889]\n",
      "[0.66666667 1.         0.88888889 1.         0.88888889]\n"
     ]
    }
   ],
   "source": [
    "# Stratified Kfold; It divides classification in a uniform way say, iron's out bias.\n",
    "# Build each def/loop for getting the score with splits using stratified kf\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=3) # and store all scores below into lists.\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "\n",
    "#  Other wise, use a pre-set def to get scores to choose best.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(rfm,X_test,y_test.values.ravel()))\n",
    "print(cross_val_score(lm,X_test,y_test.values.ravel()))\n",
    "print(cross_val_score(svcm,X_test,y_test.values.ravel()))\n",
    "print(cross_val_score(dtm,X_test,y_test.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
